# Predictive Maintenance Model on STM32L4R9

![photo de la carte](https://github.com/user-attachments/assets/dd0d17c9-4b90-44a4-a9f5-c4f6d9447f46)


## üìå Description g√©n√©rale
Ce projet a pour objectif de concevoir, entra√Æner et d√©ployer un mod√®le de r√©seau de neurones pour une t√¢che de **maintenance pr√©dictive**, en s‚Äôappuyant sur le jeu de donn√©es **AI4I 2020 Dataset**.

Le mod√®le a √©t√© entra√Æn√© √† l‚Äôaide de **Google Colab**, puis converti et d√©ploy√© pour une inf√©rence embarqu√©e sur la carte **STM32L4R9**, via **STM32Cube.AI**.  
Ce projet suit les √©tapes classiques d‚Äôun cycle de d√©veloppement en IA embarqu√©e : collecte et pr√©paration des donn√©es, entra√Ænement d‚Äôun mod√®le, √©valuation, quantification et d√©ploiement.

## üóÉÔ∏è Donn√©es utilis√©es ‚Äì AI4I 2020 Dataset
Le fichier `ai4i2020.csv` est un jeu de donn√©es de maintenance pr√©dictive compos√© de 10 000 √©chantillons simulant le fonctionnement d‚Äô√©quipements industriels. Il inclut :

- Des **donn√©es num√©riques continues** repr√©sentant des param√®tres de fonctionnement :
  - `Air temperature [K]`
  - `Process temperature [K]`
  - `Rotational speed [rpm]`
  - `Torque [Nm]`
  - `Tool wear [min]`

- Une **caract√©ristique cat√©gorielle** :
  - `Type` (L, M ou H)

- Cinq colonnes binaires indiquant la pr√©sence ou non d‚Äôun type de panne :
  - `TWF`, `HDF`, `PWF`, `OSF`, `RNF`

- Une colonne binaire `Machine failure` indiquant si une panne est survenue, sans pr√©ciser laquelle.

- Des identifiants non exploitables pour l‚Äôapprentissage : `UDI`, `Product ID`

Le dataset ne contient pas directement de colonne multiclasse indiquant le type pr√©cis de panne. Cette structure n√©cessite donc une transformation avant de pouvoir entra√Æner un mod√®le de classification multi-classes.

## üîç √âtape 1 ‚Äì Analyse et pr√©paration du jeu de donn√©es

### 1.1 Probl√®me de d√©s√©quilibre massif
D√®s les premi√®res explorations, nous avons constat√© un **d√©s√©quilibre massif** dans le dataset : la tr√®s grande majorit√© des √©chantillons sont √©tiquet√©s "No Failure" (absence de panne).

Ce d√©s√©quilibre rendait impossible l‚Äôentra√Ænement direct d‚Äôun mod√®le pertinent. En effet, un mod√®le na√Øf pouvait facilement obtenir plus de 95% de pr√©cision simplement en pr√©disant "pas de panne" tout le temps.

Ce comportement est trompeur, car s‚Äôil permet de pr√©dire correctement l‚Äôabsence de panne, il √©choue √† identifier pr√©cis√©ment le **type** de panne en cas de d√©faillance ‚Äî ce qui constitue l‚Äôobjectif r√©el du projet.

### 1.2 Nettoyage et filtrage
Pour cr√©er une cible fiable utilisable en classification, nous avons construit une nouvelle colonne `Failure Type`, √† partir des 5 colonnes binaires.

Afin d‚Äô√©viter toute ambigu√Øt√©, nous avons filtr√© le dataset pour ne conserver que :
- Les lignes o√π **aucune panne n‚Äôest pr√©sente** (toutes les colonnes TWF √† RNF sont √† 0), annot√©es comme "No Failure" ;
- Les lignes o√π **exactement une seule panne** est active (ex : TWF = 1 et toutes les autres √† 0).

Certaines lignes comportaient plusieurs pannes simultan√©ment (ex : TWF = 1 et RNF = 1). Ces cas sont trop peu nombreux pour permettre un apprentissage multi-label efficace, et trop ambigus pour √™tre trait√©s en classification simple. Elles ont donc √©t√© exclues.

Ce nettoyage nous a permis d‚Äôobtenir un jeu de donn√©es propre, avec une cible unique par √©chantillon, pour un apprentissage **multi-classes √† 6 labels** :
`No Failure`, `TWF`, `HDF`, `PWF`, `OSF`, `RNF`.

### 1.3 R√©flexion autour du multi-label
Nous avons initialement envisag√© une approche **multi-label**, dans laquelle le mod√®le pourrait pr√©dire plusieurs pannes simultan√©ment. Cette id√©e a √©t√© abandonn√©e pour plusieurs raisons :

- La proportion de lignes contenant plusieurs pannes actives √©tait **tr√®s faible**, rendant le signal difficile √† apprendre.
- Le passage au multi-label aurait n√©cessit√© un changement de strat√©gie complet :
  - Fonction de perte `binary_crossentropy` au lieu de `categorical_crossentropy`
  - Seuils d‚Äôactivation √† calibrer pour chaque sortie
  - Adaptation de l‚Äôarchitecture embarqu√©e pour interpr√©ter plusieurs sorties actives simultan√©ment

Dans le contexte d‚Äôun projet embarqu√© sur STM32, cela aurait consid√©rablement complexifi√© le d√©ploiement et la v√©rification des r√©sultats. Nous avons donc opt√© pour une classification **multi-classes classique**, plus simple, plus robuste, et surtout **mieux adapt√©e aux contraintes d‚Äôun microcontr√¥leur**.

## üå≤ √âtape 2 ‚Äì Choix du mod√®le et architecture

### 2.1 Choix du type de mod√®le : r√©seau de neurones (MLP)
Nous avons choisi d‚Äôutiliser un **r√©seau de neurones dense (MLP)** plut√¥t qu‚Äôun algorithme de type Random Forest, SVM ou arbre de d√©cision pour plusieurs raisons :
- **Compatibilit√© native avec STM32Cube.AI**, qui permet une conversion automatique des architectures Keras vers du code embarqu√© optimis√©
- Capacit√© des r√©seaux de neurones √† capturer des relations non lin√©aires dans les donn√©es industrielles continues
- Meilleure **portabilit√©** et contr√¥le de la taille m√©moire par rapport √† d‚Äôautres mod√®les plus lourds

Ce choix est √©galement coh√©rent avec les exemples fournis dans les projets de classification embarqu√©e comme MNIST sur STM32 que nous avons d√©j√† impl√©ment√© au pr√©alable.

### 2.2 Architecture du r√©seau retenue
Le mod√®le final utilis√© est un r√©seau de neurones √† 3 couches enti√®rement connect√©es :
- **Input layer** : 7 entr√©es correspondant aux 7 features num√©riques du jeu de donn√©es nettoy√©
- **Dense(128)** avec activation **ReLU**
- **Dense(64)** avec activation **ReLU**
- **Dense(6)** avec activation **Softmax**, correspondant aux 6 classes cibles : `No Failure`, `TWF`, `HDF`, `PWF`, `OSF`, `RNF`

Nous n‚Äôavons **pas utilis√© de Dropout** dans le mod√®le final, car l‚Äôoverfitting ne s‚Äôest pas av√©r√© probl√©matique apr√®s r√©√©quilibrage du dataset avec SMOTE.

![Graphe du mod√®le](https://github.com/user-attachments/assets/07a9231e-0edc-4eac-99d0-6d14d5010115)

Ce mod√®le est d√©fini dans le notebook `predictive_maintenance_model.ipynb` avec la fonction de perte `categorical_crossentropy` et l‚Äôoptimiseur `adam`.

### 2.3 Validation du mod√®le
Plut√¥t que de recourir √† une recherche d‚Äôhyperparam√®tres automatis√©e (grid search), nous avons men√© des **tests manuels successifs**. √Ä chaque it√©ration, nous avons √©valu√© le mod√®le √† l‚Äôaide de :
- **La matrice de confusion** compl√®te sur les 6 classes
- **Le rapport de classification** (`precision`, `recall`, `f1-score` par classe)

Ces outils nous ont permis d‚Äôidentifier l‚Äôarchitecture la plus √©quilibr√©e entre performance globale et bonne d√©tection des classes rares (comme RNF).

### 2.4 Adaptation √† l‚Äôembarqu√© (STM32)
L‚Äôarchitecture a √©t√© choisie pour √™tre **l√©g√®re, compacte et embarquable**, notamment :
- Aucun traitement convolutif ou s√©quentiel
- Un nombre de param√®tres ma√Ætris√© (< 20 000)
- Un seul passage avant pr√©diction (`feed-forward`) sans complexit√© algorithmique

## ‚öñÔ∏è √âtape 3 ‚Äì R√©√©quilibrage du dataset

Afin de pallier le fort d√©s√©quilibre entre les classes (notamment l‚Äô√©crasante majorit√© de "No Failure"), nous avons choisi d‚Äôappliquer une strat√©gie de **r√©√©quilibrage par oversampling**, en utilisant **SMOTE** (Synthetic Minority Over-sampling Technique).

SMOTE permet de g√©n√©rer artificiellement de nouveaux exemples pour les classes minoritaires, en interpolant des points synth√©tiques proches d‚Äô√©chantillons existants. Cette m√©thode a l‚Äôavantage de **ne pas supprimer d‚Äô√©chantillons** (contrairement √† l‚Äôundersampling), et donc de **pr√©server toute l‚Äôinformation disponible** dans le dataset initial.

Nous avons fait le choix d‚Äôutiliser uniquement SMOTE, sans tester d‚Äôautres alternatives comme les poids de classes ou le RandomUnderSampler. Bien que cela aurait pu √™tre pertinent pour comparaison, notre priorit√© √©tait d‚Äôobtenir rapidement un jeu de donn√©es √©quilibr√© pour valider l‚Äôapprentissage embarqu√©.

### Application dans le pipeline
D‚Äôapr√®s l‚Äôanalyse du code, le r√©√©quilibrage par SMOTE est effectu√© **avant le split train/test**, ce qui peut introduire un risque de **data leakage** (les points synth√©tiques pouvant influencer les deux ensembles).

Une am√©lioration possible serait d‚Äôappliquer SMOTE **uniquement sur l‚Äôensemble d‚Äôentra√Ænement** apr√®s d√©coupage, afin de pr√©server l‚Äôind√©pendance de la phase de test. Cela n‚Äôa toutefois pas sembl√© alt√©rer la qualit√© des r√©sultats dans notre cas, comme en t√©moigne la bonne g√©n√©ralisation observ√©e sur les pr√©dictions STM32.

## üéØ √âtape 4 ‚Äì √âvaluation du mod√®le

L‚Äô√©valuation de notre mod√®le ne s‚Äôest pas limit√©e √† une simple mesure d‚Äôaccuracy. Nous avons mis en place un protocole plus complet, fond√© sur des outils d‚Äôanalyse fine de la performance :

### 4.1 M√©triques utilis√©es

Nous avons utilis√© les m√©triques classiques mais essentielles pour un probl√®me de classification multi-classes :
- **Accuracy globale** : utile pour donner une id√©e g√©n√©rale des performances
- **Rapport de classification** : incluant `precision`, `recall` et `f1-score` pour chaque classe
- **Matrice de confusion** : pour visualiser les erreurs de pr√©diction classe par classe

Ces indicateurs permettent non seulement de juger la qualit√© globale du mod√®le, mais aussi de v√©rifier s‚Äôil n‚Äôest pas biais√© contre les classes minoritaires comme `RNF`.

### 4.2 Outils de visualisation

Pour renforcer l‚Äôanalyse, nous avons trac√© l‚Äô√©volution de la **loss et de l‚Äôaccuracy** en fonction des epochs sur les ensembles d‚Äôentra√Ænement et de validation. Ces courbes nous ont permis de confirmer l‚Äôabsence d‚Äôoverfitting visible et la bonne g√©n√©ralisation du mod√®le.

### 4.3 R√©sultats observ√©s

Le mod√®le atteint une pr√©cision globale sup√©rieure √† **99%**, y compris sur l‚Äôensemble de test. La matrice de confusion montre que :
- Les classes majoritaires comme `No Failure` ou `TWF` sont parfaitement pr√©dites
- Les classes plus rares comme `RNF` ou `OSF` sont √©galement bien identifi√©es, ce qui montre l‚Äôefficacit√© du r√©√©quilibrage par SMOTE

Le rapport de classification confirme une bonne homog√©n√©it√© des scores f1, avec un macro-average et un weighted-average tr√®s √©lev√©s (proches de 0.99).

### 4.4 Limites et interpr√©tation

Malgr√© ces bons r√©sultats, nous restons prudents :
- Le split train/test apr√®s SMOTE aurait pu influencer les scores positivement
- Les r√©sultats sont obtenus sur un jeu synth√©tique ; une validation sur des donn√©es r√©elles serait n√©cessaire pour garantir la robustesse du mod√®le

L‚Äôensemble des outils d‚Äô√©valuation utilis√©s nous permet de conclure que notre mod√®le est suffisamment fiable pour un d√©ploiement embarqu√© sur STM32.


## üìä √âtape 5 : Inf√©rence embarqu√©e & test
Le fichier Python `Send_data_stm32.py` pilote la communication :
- Envoie des vecteurs normalis√©s √† la carte
- Lit les 6 scores softmax en retour
- Affiche la classe pr√©dite

Une fonction d‚Äô√©valuation compare (si disponible) la sortie STM32 √† la v√©rit√© terrain. Si non, elle affiche simplement les pr√©dictions STM32 pour une inspection manuelle.

## üíß Comment ex√©cuter le projet

### Partie Python (test STM32)
```bash
python Send_data_stm32.py
```
> Assurez-vous que la carte est branch√©e, le port correct dans `PORT = "COMx"`.

### Partie Colab (entra√Ænement)
Lancez le notebook `predictive_maintenance_model.ipynb` sur Google Colab ou localement avec Jupyter.

## üìÅ Organisation des fichiers

| Fichier | R√¥le |
|--------|------|
| `predictive_maintenance_model.ipynb` | Pr√©traitement, entra√Ænement, √©valuation du mod√®le |
| `Send_data_stm32.py` | Communication UART avec la carte STM32 |
| `model.h5` | Mod√®le entra√Æn√© pr√™t √† √™tre import√© dans STM32CubeAI |
| `README.md` | Rapport complet du projet |
| `TP_AI4I2020.ipynb` | Version initiale / alternative du traitement |
| `ai4i2020.csv` | Dataset de maintenance pr√©dictive |

## üìä R√©sultats obtenus
- Le mod√®le embarqu√© est capable de pr√©dire en temps r√©el le type de panne
- La latence d‚Äôinf√©rence est tr√®s faible (quelques ms)
- La communication UART est fiable, avec pr√©dictions correctes
- Le mod√®le est suffisamment l√©ger pour une ex√©cution fluide sur STM32L4R9

## ‚úÖ Conclusion
Ce projet couvre l‚Äôensemble du cycle :
- De l‚Äôanalyse de donn√©es jusqu‚Äôau d√©ploiement embarqu√©
- Avec une architecture optimis√©e pour les contraintes d‚Äôun microcontr√¥leur
- Et une pr√©cision satisfaisante sur des donn√©es industrielles simul√©es

Il refl√®te une **int√©gration compl√®te de l‚ÄôIA embarqu√©e sur STM32**.

