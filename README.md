# Predictive Maintenance Model on STM32L4R9

![photo de la carte](https://github.com/user-attachments/assets/dd0d17c9-4b90-44a4-a9f5-c4f6d9447f46)


## üìå Description g√©n√©rale
Ce projet a pour objectif de concevoir, entra√Æner et d√©ployer un mod√®le de r√©seau de neurones pour une t√¢che de **maintenance pr√©dictive**, en s‚Äôappuyant sur le jeu de donn√©es **AI4I 2020 Dataset**.

Le mod√®le a √©t√© entra√Æn√© √† l‚Äôaide de **Google Colab**, puis converti et d√©ploy√© pour une inf√©rence embarqu√©e sur la carte **STM32L4R9**, via **STM32Cube.AI**.  
Ce projet suit les √©tapes classiques d‚Äôun cycle de d√©veloppement en IA embarqu√©e : collecte et pr√©paration des donn√©es, entra√Ænement d‚Äôun mod√®le, √©valuation, quantification et d√©ploiement.

## üóÉÔ∏è Donn√©es utilis√©es ‚Äì AI4I 2020 Dataset
Le fichier `ai4i2020.csv` est un jeu de donn√©es de maintenance pr√©dictive compos√© de 10 000 √©chantillons simulant le fonctionnement d‚Äô√©quipements industriels. Il inclut :

- Des **donn√©es num√©riques** repr√©sentant des param√®tres de fonctionnement :
  - `Air temperature [K]`
  - `Process temperature [K]`
  - `Rotational speed [rpm]`
  - `Torque [Nm]`
  - `Tool wear [min]`

- Une **caract√©ristique cat√©gorielle** :
  - `Type` (L, M ou H)

- Cinq colonnes binaires indiquant la pr√©sence ou non d‚Äôun type de panne :
  - `TWF`, `HDF`, `PWF`, `OSF`, `RNF`

- Une colonne binaire `Machine failure` indiquant si une panne est survenue, sans pr√©ciser laquelle.

- Des identifiants non exploitables pour l‚Äôapprentissage : `UDI`, `Product ID`

Le dataset ne contient pas directement de colonne multiclasse indiquant le type pr√©cis de panne. Cette structure n√©cessite donc une transformation avant de pouvoir entra√Æner un mod√®le de classification multi-classes.

## üîç √âtape 1 ‚Äì Analyse et pr√©paration du jeu de donn√©es

### 1.1 Probl√®me de d√©s√©quilibre massif
D√®s les premi√®res explorations, nous avons constat√© un **d√©s√©quilibre** dans le dataset : la tr√®s grande majorit√© des √©chantillons sont √©tiquet√©s "No Failure" (absence de panne).

Ce d√©s√©quilibre rendait impossible l‚Äôentra√Ænement direct d‚Äôun mod√®le pertinent. En effet, un mod√®le na√Øf pouvait facilement obtenir plus de 95% de pr√©cision simplement en pr√©disant "pas de panne" tout le temps.

Ce comportement est trompeur, car s‚Äôil permet de pr√©dire correctement l‚Äôabsence de panne, il √©choue √† identifier pr√©cis√©ment le **type** de panne en cas de d√©faillance ‚Äî ce qui constitue l‚Äôobjectif r√©el de notre projet.

### 1.2 Nettoyage et filtrage
Pour cr√©er une cible fiable utilisable en classification, nous avons construit une nouvelle colonne `Failure Type`, √† partir des 5 colonnes binaires.

Afin d‚Äô√©viter toute ambigu√Øt√©, nous avons filtr√© le dataset pour ne conserver que :
- Les lignes o√π **aucune panne n‚Äôest pr√©sente** (toutes les colonnes TWF √† RNF sont √† 0), annot√©es comme "No Failure" ;
- Les lignes o√π **exactement une seule panne** est active (ex : TWF = 1 et toutes les autres √† 0).

Certaines lignes comportaient plusieurs pannes simultan√©ment (ex : TWF = 1 et RNF = 1). Ces cas sont trop peu nombreux pour permettre un apprentissage multi-label efficace, et trop ambigus pour √™tre trait√©s en classification simple. Elles ont donc √©t√© exclues de l'entra√Ænement.

Ce nettoyage nous a permis d‚Äôobtenir un jeu de donn√©es propre, avec une cible unique par √©chantillon, pour un apprentissage **multi-classes √† 6 labels** :
`No Failure`, `TWF`, `HDF`, `PWF`, `OSF`, `RNF`.

### 1.3 R√©flexion autour du multi-label
Nous avons initialement envisag√© une approche **multi-label**, dans laquelle le mod√®le pourrait pr√©dire plusieurs pannes simultan√©ment. Cette id√©e a √©t√© abandonn√©e pour plusieurs raisons :

- La proportion de lignes contenant plusieurs pannes actives √©tait **tr√®s faible**, rendant le signal difficile √† apprendre.
- Le passage au multi-label aurait n√©cessit√© un changement de strat√©gie complet :
  - Fonction de perte `binary_crossentropy` au lieu de `categorical_crossentropy`
  - Seuils d‚Äôactivation √† calibrer pour chaque sortie
  - Adaptation de l‚Äôarchitecture embarqu√©e pour interpr√©ter plusieurs sorties actives simultan√©ment

Dans le contexte d‚Äôun projet embarqu√© sur STM32, cela aurait consid√©rablement complexifi√© le d√©ploiement et la v√©rification des r√©sultats. Nous avons donc opt√© pour une classification **multi-classes classique**, plus simple et surtout **mieux adapt√©e aux contraintes d‚Äôun microcontr√¥leur**.

## üå≤ √âtape 2 ‚Äì Choix du mod√®le et architecture

### 2.1 Choix du type de mod√®le : r√©seau de neurones (MLP)
Nous avons choisi d‚Äôutiliser un **r√©seau de neurones dense (MLP)** plut√¥t qu‚Äôun algorithme de type Random Forest, SVM ou arbre de d√©cision pour plusieurs raisons :
- **Compatibilit√© native avec STM32Cube.AI**, qui permet une conversion automatique des architectures Keras vers du code embarqu√© optimis√©
- Capacit√© des r√©seaux de neurones √† capturer des relations non lin√©aires dans les donn√©es industrielles continues
- Meilleure **portabilit√©** et contr√¥le de la taille m√©moire par rapport √† d‚Äôautres mod√®les plus lourds

Ce choix est √©galement coh√©rent avec les exemples fournis dans les projets de classification embarqu√©e comme MNIST sur STM32 que nous avons d√©j√† impl√©ment√© au pr√©alable comme exercice de pr√©paration pour ce projet.

### 2.2 Architecture du r√©seau retenue
Le mod√®le final utilis√© est un r√©seau de neurones √† 3 couches enti√®rement connect√©es :
- **Input layer** : 7 entr√©es correspondant aux 7 features num√©riques du jeu de donn√©es nettoy√©
- **Dense(128)** avec activation **ReLU**
- **Dense(64)** avec activation **ReLU**
- **Dense(6)** avec activation **Softmax**, correspondant aux 6 classes cibles : `No Failure`, `TWF`, `HDF`, `PWF`, `OSF`, `RNF`

Nous n‚Äôavons **pas utilis√© de Dropout** dans le mod√®le final, car l‚Äôoverfitting ne s‚Äôest pas av√©r√© probl√©matique apr√®s r√©√©quilibrage du dataset avec SMOTE.

![Graphe du mod√®le](https://github.com/user-attachments/assets/07a9231e-0edc-4eac-99d0-6d14d5010115)

Ce mod√®le est d√©fini dans le notebook `predictive_maintenance_model.ipynb` avec la fonction de perte `categorical_crossentropy` et l‚Äôoptimiseur `adam`.

### 2.3 Validation du mod√®le
Plut√¥t que de recourir √† une recherche d‚Äôhyperparam√®tres automatis√©e (grid search), nous avons men√© des **tests manuels successifs**. √Ä chaque it√©ration, nous avons √©valu√© le mod√®le √† l‚Äôaide de :
- **La matrice de confusion** compl√®te sur les 6 classes
- **Le rapport de classification** (`precision`, `recall`, `f1-score` par classe)
- **Accuracy globale** visualisation de la loss et d'accuracy

Ces outils nous ont permis d‚Äôidentifier l‚Äôarchitecture la plus √©quilibr√©e entre performance globale et bonne d√©tection des classes rares (comme RNF).

### 2.4 Adaptation √† l‚Äôembarqu√© (STM32)
L‚Äôarchitecture a √©t√© choisie pour √™tre **l√©g√®re, compacte et embarquable**, notamment :
- Aucun traitement convolutif ou s√©quentiel
- Un nombre de param√®tres ma√Ætris√© (< 20 000)
- Un seul passage avant pr√©diction (`feed-forward`) sans complexit√© algorithmique

## ‚öñÔ∏è √âtape 3 ‚Äì R√©√©quilibrage du dataset

Afin de pallier le fort d√©s√©quilibre entre les classes (notamment l‚Äô√©crasante majorit√© de "No Failure"), nous avons choisi d‚Äôappliquer une strat√©gie de **r√©√©quilibrage par oversampling**, en utilisant **SMOTE** (Synthetic Minority Over-sampling Technique).

SMOTE permet de g√©n√©rer artificiellement de nouveaux exemples pour les classes minoritaires, en interpolant des points synth√©tiques proches d‚Äô√©chantillons existants. Cette m√©thode a l‚Äôavantage de **ne pas supprimer d‚Äô√©chantillons** (contrairement √† l‚Äôundersampling), et donc de **pr√©server toute l‚Äôinformation disponible** dans le dataset initial.

Nous avons fait le choix d‚Äôutiliser uniquement SMOTE, sans tester d‚Äôautres alternatives comme les poids de classes ou le RandomUnderSampler. Bien que cela aurait pu √™tre pertinent pour comparaison, notre priorit√© √©tait d‚Äôobtenir rapidement un jeu de donn√©es √©quilibr√© pour valider l‚Äôapprentissage embarqu√©.

### Application dans le pipeline
Dans notre code, le r√©√©quilibrage par SMOTE est effectu√© **avant le split train/test**, ce qui peut introduire un risque de **data leakage** (les points synth√©tiques pouvant influencer les deux ensembles).

Une am√©lioration possible serait d‚Äôappliquer SMOTE **uniquement sur l‚Äôensemble d‚Äôentra√Ænement** apr√®s d√©coupage, afin de pr√©server l‚Äôind√©pendance de la phase de test. Malheureusement nous n'avons pas r√©ussi √† faire autrement. Cela n‚Äôa toutefois pas sembl√© alt√©rer la qualit√© des r√©sultats dans notre cas, comme en t√©moigne la bonne g√©n√©ralisation observ√©e sur les pr√©dictions STM32. 

## üéØ √âtape 4 ‚Äì √âvaluation du mod√®le

L‚Äô√©valuation de notre mod√®le ne s‚Äôest pas limit√©e √† une simple mesure d‚Äôaccuracy. Nous avons mis en place un protocole plus large, fond√© sur des outils d‚Äôanalyse de la performance :

### 4.1 M√©triques utilis√©es

Nous avons utilis√© les m√©triques classiques mais essentielles pour un probl√®me de classification multi-classes :
- **Accuracy globale** : utile pour donner une id√©e g√©n√©rale des performances
- **Rapport de classification** : incluant `precision`, `recall` et `f1-score` pour chaque classe
- **Matrice de confusion** : pour visualiser les erreurs de pr√©diction classe par classe

Ces indicateurs permettent non seulement de juger la qualit√© globale du mod√®le, mais aussi de v√©rifier s‚Äôil n‚Äôest pas biais√© contre les classes minoritaires comme `RNF`.

### 4.2 Outils de visualisation

Pour renforcer l‚Äôanalyse, nous avons trac√© l‚Äô√©volution de la **loss et de l‚Äôaccuracy** en fonction des epochs sur les ensembles d‚Äôentra√Ænement et de validation. Ces courbes nous ont permis de confirmer l‚Äôabsence d‚Äôoverfitting visible et la bonne g√©n√©ralisation du mod√®le.

### 4.3 R√©sultats observ√©s

Le mod√®le atteint une pr√©cision globale sup√©rieure √† **99%**, y compris sur l‚Äôensemble de test. La matrice de confusion montre que :
- Les classes majoritaires comme `No Failure` ou `TWF` sont parfaitement pr√©dites
- Les classes plus rares comme `RNF` ou `OSF` sont √©galement bien identifi√©es, ce qui montre l‚Äôefficacit√© du r√©√©quilibrage par SMOTE

Le rapport de classification confirme une bonne homog√©n√©it√© des scores f1, avec un macro-average et un weighted-average tr√®s √©lev√©s (proches de 0.99).

### 4.4 Limites et interpr√©tation

Malgr√© ces bons r√©sultats, nous restons prudents :
- Le split train/test apr√®s SMOTE aurait pu influencer les scores positivement
- Les r√©sultats sont obtenus sur un jeu synth√©tique ; une validation sur des donn√©es r√©elles serait n√©cessaire pour garantir la robustesse du mod√®le

L‚Äôensemble des outils d‚Äô√©valuation utilis√©s nous permet de conclure que notre mod√®le est suffisamment fiable pour un d√©ploiement embarqu√© sur STM32.


## üèπ √âtape 5 ‚Äì D√©ploiement sur la carte STM32

Le mod√®le entra√Æn√© a √©t√© export√© dans un premier temps au format `.h5`, mais cette approche a pos√© des probl√®mes de compatibilit√© lors de la conversion avec STM32Cube.AI. Nous avons donc choisi d‚Äôutiliser le format **TensorFlow Lite (`.tflite`)**, plus stable dans notre contexte. Le fichier `.tflite` a √©t√© g√©n√©r√© et stock√© sur Google Drive avant importation dans CubeMX.

### 5.1 Conversion avec STM32Cube.AI

La d√©marche suivie pour int√©grer le mod√®le sur la carte STM32 s‚Äôinspire √©troitement de l‚Äôexemple **MNIST** pr√©sent√© dans le cours (cf. EmbeddedAI.pdf). Nous avons utilis√© l‚Äôoutil **STM32Cube.AI** int√©gr√© √† **STM32CubeMX** pour :
- Importer le mod√®le `.tflite`
- G√©n√©rer le code embarqu√© compatible avec la s√©rie **STM32L4**
- Configurer les buffers d‚Äôentr√©e/sortie et la m√©moire optimis√©e (float, RAM ‚â§ 3KB, Flash ‚â§ 25KB)

Le mod√®le a √©t√© valid√© localement √† l‚Äôaide de l‚Äôoutil `stedgeai.exe validate`, qui a confirm√© sa l√©g√®ret√© (13KB de poids, 768B d'activations). La structure du r√©seau est compos√©e de 3 couches denses.

### 5.2 Modifications du code embarqu√©

Une fois le projet g√©n√©r√© dans **STM32CubeIDE**, nous avons modifi√© manuellement le fichier `app_x-cube-ai.c` pour y int√©grer :
- Une fonction `acquire_and_process_data()` pour recevoir les donn√©es d‚Äôentr√©e via **UART** en format `float32`
- Une fonction `post_process()` qui reconstruit les r√©sultats (`softmax`) en `uint8`, puis les renvoie au PC
- Une fonction de synchronisation UART (`synchronize_UART`) pour initialiser la communication

La boucle principale `MX_X_CUBE_AI_Process()` suit la structure classique :
1. Acquisition des donn√©es via UART
2. Inf√©rence avec `ai_run()`
3. Transmission des r√©sultats au PC via UART

### 5.3 Communication avec le PC (UART)

La communication est g√©r√©e par le script Python `Send_data_stm32.py`, qui utilise le port COM4 (UART) √† 115200 bauds. Le protocole fonctionne ainsi :
- G√©n√©ration de donn√©es de test simul√©es avec `generate_random_data()`
- Normalisation des donn√©es avec `StandardScaler`
- Envoi des vecteurs de 7 floats via UART
- R√©ception d‚Äôun tableau de 6 valeurs (scores softmax compress√©s entre 0 et 255)

Le script √©value ensuite la pr√©cision STM32 en comparant la classe pr√©dite √† un `y_test` al√©atoire.

### 5.4 R√©sultats embarqu√©s

D‚Äôapr√®s le fichier `resultat.txt.txt`, la pr√©diction embarqu√©e est fonctionnelle :
- Les vecteurs sont bien transmis et re√ßus
- Le STM32 renvoie des valeurs coh√©rentes de softmax
- La pr√©cision augmente it√©rativement jusqu‚Äô√† atteindre **1.00** sur 100 it√©rations de test

Les sorties telles que `b'\x00\x00\x00\x00\xff\x00'` sont bien d√©cod√©es en scores `[0.0, 0.0, 0.0, 0.0, 1.0, 0.0]`, correspondant √† des classes valides.

![resultat_test](https://github.com/user-attachments/assets/c68c72c6-4ada-4751-9aab-38605d247493)

Le mod√®le embarqu√© montre ainsi une inf√©rence rapide, fiable, et efficace, parfaitement adapt√©e √† un microcontr√¥leur STM32L4R9.

## üîú √âtape 6 ‚Äì Limites et perspectives

### 6.1 Limites identifi√©es

Malgr√© le bon fonctionnement g√©n√©ral du projet, certaines limites doivent √™tre soulign√©es :

- **R√©partition artificielle des classes** : le jeu de donn√©es a √©t√© r√©√©quilibr√© artificiellement avec SMOTE, ce qui pourrait induire un certain optimisme sur les performances.
- **Pas de donn√©es r√©elles** : les tests se basent sur des donn√©es simul√©es ou g√©n√©r√©es al√©atoirement. Cela ne refl√®te pas les conditions de production industrielle.
- **Absence de validation crois√©e** : l'√©valuation repose sur un simple split train/test, sans validation crois√©e.
- **Communication UART simplifi√©e** : le protocole UART utilis√© est simple mais sensible √† des pertes ou d√©synchronisations si non encadr√©.

### 6.2 Am√©liorations envisag√©es

Pour am√©liorer la robustesse et la port√©e du projet, plusieurs pistes sont possibles :

- **Tester le mod√®le avec des donn√©es r√©elles** issues de machines ou de capteurs industriels.
- **Utiliser d'autres techniques de r√©√©quilibrage** (class weighting, undersampling combin√©).
- **Passer √† une classification multi-label** si plusieurs pannes peuvent coexister (avec une autre architecture).
- **Int√©grer un syst√®me de journalisation c√¥t√© STM32**, avec sauvegarde en m√©moire Flash ou envoi p√©riodique vers le PC.
- **Mesurer le temps d'inf√©rence embarqu√©** pour √©valuer l'efficacit√© du mod√®le sur STM32.

Ces perspectives permettent de prolonger le projet vers une version plus industrialisable ou int√©gr√©e dans un pipeline de maintenance pr√©dictive en environnement embarqu√© r√©el.

## ‚úÖ Conclusion g√©n√©rale

Ce projet a permis de mettre en ≈ìuvre l‚Äôensemble de la cha√Æne de d√©veloppement d‚Äôun syst√®me d‚Äôintelligence artificielle embarqu√©, depuis l‚Äôanalyse exploratoire des donn√©es jusqu‚Äôau d√©ploiement effectif sur une carte STM32.

Nous avons d√ª faire face √† des contraintes concr√®tes : d√©s√©quilibre des classes, limitations mat√©rielles, conversion du mod√®le, communication s√©rie. Chacune a √©t√© trait√©e par des choix techniques appropri√©s, justifi√©s par les contraintes du d√©ploiement embarqu√©.

Le mod√®le entra√Æn√© est pr√©cis, et op√©rationnel sur STM32. La d√©monstration de bout en bout valide la faisabilit√© d‚Äôint√©grer un algorithme de classification complexe dans un microcontr√¥leur √† ressources limit√©es.

Ce projet constitue une base pour des applications r√©elles de maintenance pr√©dictive dans un environnement industriel connect√© (IIoT).

## üíß Comment ex√©cuter le projet

### Partie Python (test STM32)
```bash
python Send_data_stm32.py
```
> Assurez-vous que la carte STM32 est bien connect√©e, et que le port s√©rie dans le script (`PORT = "COMx"`) correspond au bon port COM. Le script envoie des vecteurs de donn√©es simul√©es normalis√©es, puis re√ßoit la pr√©diction de la carte au format compress√© (softmax cod√© sur 8 bits).

### Partie Google Colab / Jupyter (entra√Ænement du mod√®le)
Ouvrir le notebook `predictive_maintenance_model.ipynb` sur Google Colab ou localement avec Jupyter Notebook pour :
- Charger et pr√©parer le jeu de donn√©es
- Appliquer le r√©√©quilibrage
- Entra√Æner le mod√®le
- √âvaluer sa performance
- Sauvegarder le mod√®le au format `.tflite` pour d√©ploiement

---

# üìÅ Organisation des fichiers

| Fichier | R√¥le |
|--------|------|
| `predictive_maintenance_model.ipynb` | Pr√©traitement, entra√Ænement et √©valuation du mod√®le |
| `Send_data_stm32.py` | Script de communication UART entre le PC et la carte STM32 |
| `model.tflite` | Mod√®le entra√Æn√© et converti, pr√™t pour STM32Cube.AI |
| `app_x-cube-ai.c` | Code C g√©n√©r√© et modifi√© pour ex√©cuter le mod√®le sur STM32 avec communication UART |
| `TP_AI4I2020.ipynb` | Version initiale / exploration pr√©liminaire du dataset |
| `ai4i2020.csv` | Jeu de donn√©es original utilis√© pour l'entra√Ænement |
| `README.md` | Rapport de projet d√©taill√© et instructions d'ex√©cution |
