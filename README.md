# Predictive Maintenance Model on STM32L4R9

![photo de la carte](https://github.com/user-attachments/assets/dd0d17c9-4b90-44a4-a9f5-c4f6d9447f46)


## üìå Description g√©n√©rale
Ce projet a pour objectif de concevoir, entra√Æner et d√©ployer un mod√®le de r√©seau de neurones pour une t√¢che de **maintenance pr√©dictive**, en s‚Äôappuyant sur le jeu de donn√©es **AI4I 2020 Dataset**.

Le mod√®le a √©t√© entra√Æn√© √† l‚Äôaide de **Google Colab**, puis converti et d√©ploy√© pour une inf√©rence embarqu√©e sur la carte **STM32L4R9**, via **STM32Cube.AI**.  
Ce projet suit les √©tapes classiques d‚Äôun cycle de d√©veloppement en IA embarqu√©e : collecte et pr√©paration des donn√©es, entra√Ænement d‚Äôun mod√®le, √©valuation, quantification et d√©ploiement.

## üóÉÔ∏è Donn√©es utilis√©es ‚Äì AI4I 2020 Dataset
Le fichier `ai4i2020.csv` est un jeu de donn√©es de maintenance pr√©dictive compos√© de 10 000 √©chantillons simulant le fonctionnement d‚Äô√©quipements industriels. Il inclut :

- Des **donn√©es num√©riques continues** repr√©sentant des param√®tres de fonctionnement :
  - `Air temperature [K]`
  - `Process temperature [K]`
  - `Rotational speed [rpm]`
  - `Torque [Nm]`
  - `Tool wear [min]`

- Une **caract√©ristique cat√©gorielle** :
  - `Type` (L, M ou H)

- Cinq colonnes binaires indiquant la pr√©sence ou non d‚Äôun type de panne :
  - `TWF`, `HDF`, `PWF`, `OSF`, `RNF`

- Une colonne binaire `Machine failure` indiquant si une panne est survenue, sans pr√©ciser laquelle.

- Des identifiants non exploitables pour l‚Äôapprentissage : `UDI`, `Product ID`

Le dataset ne contient pas directement de colonne multiclasse indiquant le type pr√©cis de panne. Cette structure n√©cessite donc une transformation avant de pouvoir entra√Æner un mod√®le de classification multi-classes.

## üîç √âtape 1 ‚Äì Analyse et pr√©paration du jeu de donn√©es

### 1.1 Probl√®me de d√©s√©quilibre massif
D√®s les premi√®res explorations, nous avons constat√© un **d√©s√©quilibre massif** dans le dataset : la tr√®s grande majorit√© des √©chantillons sont √©tiquet√©s "No Failure" (absence de panne).

Ce d√©s√©quilibre rendait impossible l‚Äôentra√Ænement direct d‚Äôun mod√®le pertinent. En effet, un mod√®le na√Øf pouvait facilement obtenir plus de 95% de pr√©cision simplement en pr√©disant "pas de panne" tout le temps.

Ce comportement est trompeur, car s‚Äôil permet de pr√©dire correctement l‚Äôabsence de panne, il √©choue √† identifier pr√©cis√©ment le **type** de panne en cas de d√©faillance ‚Äî ce qui constitue l‚Äôobjectif r√©el du projet.

### 1.2 Nettoyage et filtrage
Pour cr√©er une cible fiable utilisable en classification, nous avons construit une nouvelle colonne `Failure Type`, √† partir des 5 colonnes binaires.

Afin d‚Äô√©viter toute ambigu√Øt√©, nous avons filtr√© le dataset pour ne conserver que :
- Les lignes o√π **aucune panne n‚Äôest pr√©sente** (toutes les colonnes TWF √† RNF sont √† 0), annot√©es comme "No Failure" ;
- Les lignes o√π **exactement une seule panne** est active (ex : TWF = 1 et toutes les autres √† 0).

Certaines lignes comportaient plusieurs pannes simultan√©ment (ex : TWF = 1 et RNF = 1). Ces cas sont trop peu nombreux pour permettre un apprentissage multi-label efficace, et trop ambigus pour √™tre trait√©s en classification simple. Elles ont donc √©t√© exclues.

Ce nettoyage nous a permis d‚Äôobtenir un jeu de donn√©es propre, avec une cible unique par √©chantillon, pour un apprentissage **multi-classes √† 6 labels** :
`No Failure`, `TWF`, `HDF`, `PWF`, `OSF`, `RNF`.

### 1.3 R√©flexion autour du multi-label
Nous avons initialement envisag√© une approche **multi-label**, dans laquelle le mod√®le pourrait pr√©dire plusieurs pannes simultan√©ment. Cette id√©e a √©t√© abandonn√©e pour plusieurs raisons :

- La proportion de lignes contenant plusieurs pannes actives √©tait **tr√®s faible**, rendant le signal difficile √† apprendre.
- Le passage au multi-label aurait n√©cessit√© un changement de strat√©gie complet :
  - Fonction de perte `binary_crossentropy` au lieu de `categorical_crossentropy`
  - Seuils d‚Äôactivation √† calibrer pour chaque sortie
  - Adaptation de l‚Äôarchitecture embarqu√©e pour interpr√©ter plusieurs sorties actives simultan√©ment

Dans le contexte d‚Äôun projet embarqu√© sur STM32, cela aurait consid√©rablement complexifi√© le d√©ploiement et la v√©rification des r√©sultats. Nous avons donc opt√© pour une classification **multi-classes classique**, plus simple, plus robuste, et surtout **mieux adapt√©e aux contraintes d‚Äôun microcontr√¥leur**.

## üîç √âtape 2 ‚Äì Choix du mod√®le et architecture

### 2.1 Choix du type de mod√®le : r√©seau de neurones (MLP)
Nous avons choisi d‚Äôutiliser un **r√©seau de neurones dense (MLP)** plut√¥t qu‚Äôun algorithme de type Random Forest, SVM ou arbre de d√©cision pour plusieurs raisons :
- **Compatibilit√© native avec STM32Cube.AI**, qui permet une conversion automatique des architectures Keras vers du code embarqu√© optimis√©
- Capacit√© des r√©seaux de neurones √† capturer des relations non lin√©aires dans les donn√©es industrielles continues
- Meilleure **portabilit√©** et contr√¥le de la taille m√©moire par rapport √† d‚Äôautres mod√®les plus lourds

Ce choix est √©galement coh√©rent avec les exemples fournis dans les projets de classification embarqu√©e comme MNIST sur STM32 que nous avons d√©j√† impl√©ment√© au pr√©alable.

### 2.2 Architecture du r√©seau retenue
Le mod√®le final utilis√© est un r√©seau de neurones √† 3 couches enti√®rement connect√©es :
- **Input layer** : 7 entr√©es correspondant aux 7 features num√©riques du jeu de donn√©es nettoy√©
- **Dense(128)** avec activation **ReLU**
- **Dense(64)** avec activation **ReLU**
- **Dense(6)** avec activation **Softmax**, correspondant aux 6 classes cibles : `No Failure`, `TWF`, `HDF`, `PWF`, `OSF`, `RNF`

Nous n‚Äôavons **pas utilis√© de Dropout** dans le mod√®le final, car l‚Äôoverfitting ne s‚Äôest pas av√©r√© probl√©matique apr√®s r√©√©quilibrage du dataset avec SMOTE.

![Graphe du mod√®le](https://github.com/user-attachments/assets/07a9231e-0edc-4eac-99d0-6d14d5010115)

Ce mod√®le est d√©fini dans le notebook `predictive_maintenance_model.ipynb` avec la fonction de perte `categorical_crossentropy` et l‚Äôoptimiseur `adam`.

### 2.3 Validation du mod√®le
Plut√¥t que de recourir √† une recherche d‚Äôhyperparam√®tres automatis√©e (grid search), nous avons men√© des **tests manuels successifs**. √Ä chaque it√©ration, nous avons √©valu√© le mod√®le √† l‚Äôaide de :
- **La matrice de confusion** compl√®te sur les 6 classes
- **Le rapport de classification** (`precision`, `recall`, `f1-score` par classe)

Ces outils nous ont permis d‚Äôidentifier l‚Äôarchitecture la plus √©quilibr√©e entre performance globale et bonne d√©tection des classes rares (comme RNF).

### 2.4 Adaptation √† l‚Äôembarqu√© (STM32)
L‚Äôarchitecture a √©t√© choisie pour √™tre **l√©g√®re, compacte et embarquable**, notamment :
- Aucun traitement convolutif ou s√©quentiel
- Un nombre de param√®tres ma√Ætris√© (< 20 000)
- Un seul passage avant pr√©diction (`feed-forward`) sans complexit√© algorithmique

## üìâ √âtape 3 : √âvaluation du mod√®le
- **Accuracy > 99%**, mais ajust√©e avec des m√©triques comme le **recall** par classe.
- Une **matrice de confusion compl√®te 6√ó6** est g√©n√©r√©e dans le Colab.
- Chaque classe est correctement identifi√©e gr√¢ce √† la correction du d√©s√©quilibre et du one-hot encoding.

## üöÄ √âtape 4 : D√©ploiement sur STM32
Le mod√®le est export√© au format `tflite` (probl√®me de compatibilit√© avec h5) et import√© dans **STM32Cube.AI** via CubeMX :
- Le r√©seau est converti automatiquement en code C optimis√©
- L'inf√©rence est int√©gr√©e dans un projet STM32CubeIDE (carte STM32L4R9)
- La communication UART permet d‚Äôenvoyer les features et de recevoir la pr√©diction

Cette √©tape suit une d√©marche identique √† celle de l'exemple MNIST sur STM32 vu pr√©c√©demment en cours.

## üìä √âtape 5 : Inf√©rence embarqu√©e & test
Le fichier Python `Send_data_stm32.py` pilote la communication :
- Envoie des vecteurs normalis√©s √† la carte
- Lit les 6 scores softmax en retour
- Affiche la classe pr√©dite

Une fonction d‚Äô√©valuation compare (si disponible) la sortie STM32 √† la v√©rit√© terrain. Si non, elle affiche simplement les pr√©dictions STM32 pour une inspection manuelle.

## üíß Comment ex√©cuter le projet

### Partie Python (test STM32)
```bash
python Send_data_stm32.py
```
> Assurez-vous que la carte est branch√©e, le port correct dans `PORT = "COMx"`.

### Partie Colab (entra√Ænement)
Lancez le notebook `predictive_maintenance_model.ipynb` sur Google Colab ou localement avec Jupyter.

## üìÅ Organisation des fichiers

| Fichier | R√¥le |
|--------|------|
| `predictive_maintenance_model.ipynb` | Pr√©traitement, entra√Ænement, √©valuation du mod√®le |
| `Send_data_stm32.py` | Communication UART avec la carte STM32 |
| `model.h5` | Mod√®le entra√Æn√© pr√™t √† √™tre import√© dans STM32CubeAI |
| `README.md` | Rapport complet du projet |
| `TP_AI4I2020.ipynb` | Version initiale / alternative du traitement |
| `ai4i2020.csv` | Dataset de maintenance pr√©dictive |

## üìä R√©sultats obtenus
- Le mod√®le embarqu√© est capable de pr√©dire en temps r√©el le type de panne
- La latence d‚Äôinf√©rence est tr√®s faible (quelques ms)
- La communication UART est fiable, avec pr√©dictions correctes
- Le mod√®le est suffisamment l√©ger pour une ex√©cution fluide sur STM32L4R9

## ‚úÖ Conclusion
Ce projet couvre l‚Äôensemble du cycle :
- De l‚Äôanalyse de donn√©es jusqu‚Äôau d√©ploiement embarqu√©
- Avec une architecture optimis√©e pour les contraintes d‚Äôun microcontr√¥leur
- Et une pr√©cision satisfaisante sur des donn√©es industrielles simul√©es

Il refl√®te une **int√©gration compl√®te de l‚ÄôIA embarqu√©e sur STM32**.

